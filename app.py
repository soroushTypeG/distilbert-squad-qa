import gradio as grimport loggingfrom transformers import pipeline, AutoModelForQuestionAnswering, AutoTokenizerfrom database import load_contexts_from_db# Set up logginglogging.basicConfig(level=logging.INFO)logger = logging.getLogger(__name__)# Load model & tokenizerlogger.info("Loading fine-tuned model and tokenizer...")model_path = "./trained_model"model = AutoModelForQuestionAnswering.from_pretrained(model_path)tokenizer = AutoTokenizer.from_pretrained(model_path)# Create QA pipelinelogger.info("Creating QA pipeline")qa_pipeline = pipeline(    "question-answering",    model=model,    tokenizer=tokenizer,    max_answer_len=300,    handle_long_context=True)# LOAD CONTEXTS FROM DATABASEcontexts = load_contexts_from_db()if not contexts:    raise ValueError("No contexts found in the database. Please populate the DB first.")title_counts = {}for c in contexts:    original_title = c["title"]    if original_title in title_counts:        title_counts[original_title] += 1        c["title"] = f"{original_title} ({title_counts[original_title]})"    else:        title_counts[original_title] = 1# Gradio Interfacelogger.info("Launching Gradio interface")def qa_function(context_choice: str, question: str):    """    Process the question and return the context + model answer.    """    if not context_choice:        return "Please select a context.", ""    # Find the selected context by title    selected = next((con for con in contexts if con["title"] == context_choice), None)    if not selected:        return "Context not found.", ""    context_text = selected["text"]    if not question.strip():        return context_text, "Please enter a question."    try:        result = qa_pipeline(question=question, context=context_text)        output_answer = (            f"**Answer:** {result['answer']}\n"        )        return context_text, output_answer    except Exception as ex:        error_msg = f"Error: {str(ex)}\n(Make sure the question is in English)"        return context_text, error_msgdef update_context(choice: str):    """Update the displayed context when the dropdown changes."""    if not choice:        return ""    selected = next((index for index in contexts if index["title"] == choice), None)    return selected["text"] if selected else ""with gr.Blocks(title="SQuAD Question Answering â€“ Fine-tuned DistilBERT") as demo:    gr.Markdown("# SQuAD Question Answering Demo")    gr.Markdown(        "A fine-tuned DistilBERT model for extractive question answering "        "trained on a subset of the SQuAD v1.1 dataset."    )    gr.Markdown(        "**Important:**  \n"        "This model is fine-tuned exclusively on English data (SQuAD).  \n"        "**For best results, please ask questions in English.**"    )    with gr.Row():        context_dropdown = gr.Dropdown(            choices=[c["title"] for c in contexts],            value=contexts[0]["title"] if contexts else None,            label="Select Context",            interactive=True        )    context_display = gr.Textbox(        label="Context Text",        lines=10,        interactive=False,        value=contexts[0]["text"] if contexts else ""    )    question_input = gr.Textbox(        label="Your Question",        lines=2,        placeholder="Type in English."    )    answer_output = gr.Markdown(label="Model Answer")    # Events    context_dropdown.change(        fn=update_context,        inputs=context_dropdown,        outputs=context_display    )    gr.Button("Get Answer").click(        fn=qa_function,        inputs=[context_dropdown, question_input],        outputs=[context_display, answer_output]    )# Launchdemo.launch(share=True)